@inproceedings{pub14164,
    author = {Kuznetsov, Konstantin and Barz, Michael and Sonntag, Daniel
},
    title = {Detection of Contract Cheating in Pen-and-Paper Exams through the Analysis of Handwriting Style},
    booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction. ACM International Conference on Multimodal Interaction (ICMI-2023), October 9-13, Paris, France},
    series = {ICMI '23 Companion},
    year = {2023},
    pages = {26--30},
    publisher = {Association for Computing Machinery},
    isbn = {9798400703218}
}

@inbook{pub14630,
    author = {Kadir, Md Abdul and Addluri, Gowthamkrishna and Sonntag, Daniel
},
    editor = {Seipel, Dietmar and Steen, Alexander
},
    title = {Harmonizing Feature Attributions Across Deep Learning Architectures: Enhancing Interpretability and Consistency},
    booktitle = {German Conference on Artificial Intelligence},
    series = {Lecture Notes in Computer Science},
    year = {2023},
    pages = {90--97},
    publisher = {Springer, Cham},
    isbn = {978-3-031-42607-0}
}

@inproceedings{pub14635,
    author = {Kadir, Md Abdul and Alam, Hasan Md Tusfiqur and Sonntag, Daniel
},
    title = {EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation},
    booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention. Medical Image Computing and Computer Assisted Intervention (MICCAI-2023)},
    year = {2023},
    pages = {79--89},
    organization = {Springer},
    publisher = {Springer, Cham}
}

@inproceedings{pub14708,
    author = {Kadir, Md Abdul and Mosavi, Amir and Sonntag, Daniel
},
    title = {Evaluation Metrics for XAI: A Review, Taxonomy, and Practical Applications},
    booktitle = {2023 IEEE 27th International Conference on Intelligent Engineering Systems (INES). Conference on Intelligent Engineering Systems (INES-2023), Kenya},
    year = {2023},
    pages = {000111--000124},
    publisher = {IEEE}
}

@techreport{pub14711,
    author = {Kath, Hannes and Gouvea, Thiago and Sonntag, Daniel
},
    title = {A Deep Generative Model for Interactive Data Annotation through Direct Manipulation in Latent Space},
    series = {DFKI Research Reports (RR)},
    year = {2023},
    month = {5},
    volume = {2305.15337v1},
    pages = {7},
    institution = {DFKI}
}

@techreport{pub14710,
    author = {Kath, Hannes and Lüers, Bengt and Gouvea, Thiago and Sonntag, Daniel
},
    title = {A Virtual Reality Tool for Representing, Visualizing and Updating Deep Learning Models},
    series = {DFKI Research Reports (RR)},
    year = {2023},
    month = {5},
    volume = {2305.15353v1},
    pages = {8},
    institution = {DFKI}
}

@article{pub14707,
    author = {Sonntag, Daniel
},
    title = {Avoid Predatory Journals},
    year = {2023},
    month = {5},
    volume = {37},
    pages = {1--3},
    journal = {KI - Künstliche Intelligenz, German Journal on Artificial Intelligence - Organ des Fachbereiches "Künstliche Intelligenz" der Gesellschaft für Informatik e.V. (KI)},
    publisher = {Springer Berlin Heidelberg}
}

@inproceedings{pub14706,
    author = {Bunde, Enrico and Eisenhardt, Daniel and Sonntag, Daniel and Profitlich, Hans-Jürgen and Meske, Christian
},
    title = {Giving DIAnA More TIME – Guidance for the Design of XAI-Based Medical Decision Support Systems},
    booktitle = {18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023. International Conference on Design Science Research in Information Systems and Technology (DESRIST-2023)},
    year = {2023},
    month = {5},
    publisher = {Springer Nature Switzerland}
}

article{pub14703,
    author = {Kopácsi, László and Baffy, Benjámin and Baranyi, Gábor and Skaf, Joul and Sörös, Gábor and Szeier, Szilvia and Lőrincz, András and Sonntag, Daniel
},
    title = {Cross-Viewpoint Semantic Mapping: Integrating Human and Robot Perspectives for Improved 3D Semantic Reconstruction},
    year = {2023},
    month = {5},
    volume = {23},
    number = {11},
    pages = {1--17},
    journal = {Sensors - Open Access Journal (Sensors)},
    publisher = {MDPI}
}

@inproceedings{pub14739,
    author = {Troshani, Ilira and Gouvea, Thiago and Sonntag, Daniel
},
    title = {Leveraging Sound Collections for Animal Species Classification with Weakly Supervised Learning},
    booktitle = {3rd Annual AAAI Workshop on AI to Accelerate Science and Engineering. AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE-2024), befindet sich AAAI, Vancouver, Canada},
    year = {2024}
}

@inproceedings{pub14738,
    author = {Lüers, Bengt and Serafini, Patricia P. and Campos, Ivan Braga and Gouvea, Thiago and Sonntag, Daniel
},
    title = {BirdNET-Annotator: AI-Assisted Strong Labelling of Bird Sound Datasets},
    booktitle = {3rd Annual AAAI Workshop on AI to Accelerate Science and Engineering. AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE), befindet sich AAAI, Vancouver, Canada},
    year = {2024}
}

@inproceedings{pub14737,
    author = {Kath, Hannes and Serafini, Patricia P. and Campos, Ivan Braga and Gouvea, Thiago and Sonntag, Daniel},
    title = {Leveraging Transfer Learning and Active Learning for Sound Event Detection in Passive Acoustic Monitoring of Wildlife},
    booktitle = {3rd Annual AAAI Workshop on AI to Accelerate Science and Engineering. AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE-2024), befindet sich AAAI, Vancouver, Canada},
    year = {2024}
}

@article{pub14732,
    author = {Damm, Werner and Fränzle, Martin and Kerscher, Alyssa J. and Laine, Forrest and Bengler, Klaus and Biebl, Bianca and Hagemann, Willem and Held, Moritz
and Hess, David and Ihme, Klas and Kacianka, Severin and Lehnhoff, Sebastian and Lüdtke, Andreas and Pretschner, Alexander and Rakow, Astrid and Rieger, Jochem W. and 
Sonntag, Daniel and Sztipanovits, Janos and Schwammberger, Maike and Schweda, Mark and Trende, Alexander and Unni, Anirudh and Veith, Eric M. S. P.
},
    title = {A Reference Architecture of Human Cyber-Physical Systems - Part III: Semantic Foundations},
    year = {2024},
    volume = {8},
    number = {1},
    pages = {1--23},
    journal = {ACM Transactions on Cyber-Physical Systems (TCPS)},
    publisher = {ACM}
}

@inproceedings{pub14721,
    author = {Liang, Siting and Sánchez, Pablo Valdunciel and Sonntag, Daniel
},
    title = {Optimizing Relation Extraction in Medical Texts through Active Learning: A Comparative Analysis of Trade-offs},
    booktitle = {Association for Computational Linguistics. Conference of the European Chapter of the Association for Computational Linguistics (EACL-2024), March 17-22, Malta, Malta},
    year = {2024},
    publisher = {ACL Anthology}
}

@inbook{pub14702,
    author = {Barz, Michael and Karagiannis, Panagiotis and Kildal, Johan and Pinto, Andoni Rivera and Munain, Judit Ruiz de and Rosel, Jesús and Madarieta, Maria 
and Salagianni, Konstantina and Aivaliotis, Panagiotis and Makris, Sotiris and Sonntag, Daniel
},
    editor = {Alam, Mohammad-Reza and Fathi, Madjid},
    title = {MASTER-XR: Mixed reAlity ecoSystem for TEaching Robotics in manufacturing},
    booktitle = {Integrated Systems: Innovations and Applications: Results of the 8th International Conference on Integrated Systems Design and Technology (ISDT 2023)},
    year = {2024},
    pages = {1--16},
    publisher = {Springer},
    isbn = {3031536517}
}

@article{pub14705,
    author = {Damm, Werner and Hess, David and Schweda, Mark and Sztipanovits, Janos and Bengler, Klaus and Biebl, Bianca and Fränzle, Martin and Hagemann, Willem
and Held, Moritz and Ihme, Klas and Kacianka, Severin and Kerscher, Alyssa J and Lehnhoff, Sebastian and Luedtke, Andreas and Pretschner, Alexander and Rakow, Astrid
 and Rieger, Jochem and Sonntag, Daniel and Schwammberger, Maike and Austel, Benedikt and Unni, Anirudh and Veith, Eric
},
    title = {A Reference Architecture of Human Cyber-Physical Systems – Part I: Fundamental Concepts},
    year = {2024},
    month = {1},
    volume = {8},
    pages = {1--32},
    journal = {ACM Transactions on Cyber-Physical Systems (TCPS)},
    publisher = {ACM}
}


@article{pub14704,
    author = {Bengler, Klaus and Damm, Werner and Luedtke, Andreas and Rieger, Jochem and Austel, Benedikt and Biebl, 
Bianca and Fränzle, Martin and Hagemann, Willem and Held, Moritz and Hess, David and Ihme, Klas and Kacianka, Severin 
and Kerscher, Alyssa J and Laine, Forrest and Lehnhoff, Sebastian and Pretschner, Alexander and Rakow, Astrid 
and Sonntag, Daniel and Sztipanovits, Janos and Schwammberger, Maike and Schweda, Mark and  Unni, Anirudh and Veith, Eric
},
    title = {A References Architecture for Human Cyber Physical Systems, Part II: Fundamental Design Principles for Human-CPS Interaction},
    year = {2024},
    month = {1},
    volume = {8},
    pages = {1--27},
    journal = {ACM Transactions on Cyber-Physical Systems (TCPS)},
    publisher = {ACM}
}


@inproceedings{pub14648,
    author = {Kath, Hannes and Lüers, Bengt and Gouvea, Thiago and Sonntag, Daniel},
    editor = {Seipel, Dietmar and Steen, Alexander},
    title = {Lost in Dialogue: A Review and Categorisation of Current Dialogue System Approaches and Technical Solutions},
    booktitle = {KI 2023: Advances in Artificial Intelligence. German Conference on Artificial Intelligence (KI-2023), 46th German Conference on AI, Berlin, Germany, September 26–29, 2023, Proceedings, befindet sich 46th German Conference on AI, September 26-29, Berlin, Germany},
    series = {Lecture Notes in Artificial Intelligence (LNAI)},
    year = {2023},
    month = {9},
    volume = {14236},
    pages = {98--113},
    publisher = {Springer},
    isbn = {978-3-031-42607-0}
}

@inproceedings{pub13988,
    author = {Johns, Christoph Albert and Barz, Michael and Sonntag, Daniel},
    editor = {Seipel, Dietmar and Steen, Alexander},
    title = {Interactive Link Prediction as a Downstream Task for Foundational GUI Understanding Models},
    booktitle = {KI 2023: Advances in Artificial Intelligence. German Conference on Artificial Intelligence (KI-2023), Berlin, Germany},
    year = {2023},
    month = {9},
    pages = {75--89},
    publisher = {Springer Nature Switzerland},
    isbn = {978-3-031-42608-7}
}

@inproceedings{pub14499,
    author = {Nguyen, Ho Minh Duy and Pham, Tan and Diep, Nghiem Tuong and Phan, Nghi and Pham, Quang and Tong, Vinh and Nguyen, Binh T. and Le, Ngan Hoang and Ho, Nhat and Xie, Pengtao and Sonntag, Daniel and Niepert, Mathias},
    title = {On the Out of Distribution Robustness of Foundation Models in Medical Image Segmentation},
    booktitle = {The Thirty-Seventh Annual Conference on Neural Information Processing Systems (NeurIPS 2023). Neural Information Processing Systems (NeurIPS), Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models, December 10-16},
    year = {2023},
    month = {12},
    publisher = {Advances in Neural Information Processing Systems}
}

@inproceedings{pub14309,
    author = {Nguyen, Ho Minh Duy and Nguyen, Hoang and Diep, Nghiem T. and Pham, Tan and Cao, Tri and Nguyen, Binh T. and Swoboda, Paul and Ho, Nhat and Albarqouni, Shadi and Xie, Pengtao and Sonntag, Daniel and Niepert, Mathias},
    title = {LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching},
    booktitle = {The Thirty-Seventh Annual Conference on Neural Information Processing Systems (NeurIPS 2023). Neural Information Processing Systems (NeurIPS), December 10-16, United States},
    year = {2023},
    month = {12},
    publisher = {Advances in Neural Information Processing Systems}
}

@inproceedings{pub13402,
author = {Liang, Siting and Hartmann, Mareike and Sonntag, Daniel},
title = {Cross-domain German Medical Named Entity Recognition using a Pre-Trained Language Model and Unified Medical Semantic Types},
booktitle = {Association for Computational Linguistics. Clinical Natural Language Processing Workshop (ClinicalNLP-2023), July 9-14, Toronto, Canada},
year = {2023},
publisher = {ACL}
}

@inproceedings{pub13395,
author = {Kath, Hannes Berthold and Gouvea, Thiago and Sonntag, Daniel},
title = {A Human-in-the-Loop Tool for Annotating Passive Acoustic Monitoring Datasets},
booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence. International Joint Conference on Artificial Intelligence (IJCAI-2023), located at IJCAI, August 19-25, Macao, Macao. International Joint Conference on Artificial Intelligence (IJCAI), befindet sich IJCAI, August 19-25, Macao, China},
year = {2023},
publisher = {International Joint Conferences on Artificial Intelligence}
}

@inproceedings{pub13356,
author = {Gouvea, Thiago and Kath, Hannes Berthold and Troshani, Ilira and Lüers, Bengt and Serafini, Patrícia P. and Campos, Ivan B. and Afonso, André S. and Leandro, Sérgio M. F. M. and Swanepoel, Lourens and Theron, Nicholas and Swemmer, Anthony M. and Sonntag, Daniel},
title = {Interactive Machine Learning Solutions for Acoustic Monitoring of Animal Wildlife in Biosphere Reserves},
booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence. International Joint Conference on Artificial Intelligence (IJCAI-2023), befindet sich IJCAI, August 19-25, Macao, Macao SAR of China},
year = {2023},
publisher = {International Joint Conferences on Artificial Intelligence}
}

@inproceedings{pub13420,
author = {Anagnostopoulou, Aliki and Hartmann, Mareike and Sonntag, Daniel},
title = {Towards Adaptable and Interactive Image Captioning with Data Augmentation and Episodic Memory},
booktitle = {Proceedings of The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP). ACL Workshop on Simple and Efficient Natural Language Processing (SustaiNLP-2023), befindet sich Annual Meeting of the Association for Computational Linguistics 2023, July 13-13, Toronto, Canada},
year = {2023},
month = {7},
publisher = {Association for Computational Linguistics}
}

@inproceedings{13200,
title = {A User Interface for Explaining Machine Learning Model Explanations},
author = {Md Abdul Kadir and Abdulrahman Mohamed Selim and Michael Barz and Daniel Sonntag},
url = {https://doi.org/10.1145/3581754.3584131},
doi = {10.1145/3581754.3584131},
isbn = {9798400701078},
year = {2023},
date = {2023-01-01},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {59–63},
publisher = {Association for Computing Machinery},
address = {Sydney, NSW, Australia},
series = {IUI '23 Companion},
abstract = {Explainable Artificial Intelligence (XAI) is an emerging subdiscipline of Machine Learning (ML) and human-computer interaction. Discriminative models need to be understood. An explanation of such ML models is vital when an AI system makes decisions that have significant consequences, such as in healthcare or finance. By providing an input-specific explanation, users can gain confidence in an AI system’s decisions and be more willing to trust and rely on it. One problem is that interpreting example-based explanations for discriminative models, such as saliency maps, can be difficult because it is not always clear how the highlighted features contribute to the model’s overall prediction or decisions. Moreover, saliency maps, which are state-of-the-art visual explanation methods, do not provide concrete information on the influence of particular features. We propose an interactive visualisation tool called EMILE-UI that allows users to evaluate the provided explanations of an image-based classification task, specifically those provided by saliency maps. This tool allows users to evaluate the accuracy of a saliency map by reflecting the true attention or focus of the corresponding model. It visualises the relationship between the ML model and its explanation of input images, making it easier to interpret saliency maps and understand how the ML model actually predicts. Our tool supports a wide range of deep learning image classification models and image data as inputs.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@inproceedings{13201,
title = {IMETA: An Interactive Mobile Eye Tracking Annotation Method for Semi-Automatic Fixation-to-AOI Mapping},
author = {László Kopácsi and Michael Barz and Omair Shahzad Bhatti and Daniel Sonntag},
url = {https://www.dfki.de/fileadmin/user_upload/import/13201_3581754.3584125.pdf},
doi = {https://doi.org/10.1145/3581754.3584125},
year = {2023},
date = {2023-01-01},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {33-36},
publisher = {Association for Computing Machinery},
abstract = {Mobile eye tracking studies involve analyzing areas of interest (AOIs) and visual attention to these AOIs to understand how people process visual information. However, accurately annotating the data collected for user studies can be a challenging and time-consuming task. Current approaches for automatically or semi-automatically analyzing head-mounted eye tracking data in mobile eye tracking studies have limitations, including a lack of annotation flexibility or the inability to adapt to specific target domains. To address this problem, we present IMETA, an architecture for semi-automatic fixation-to-AOI mapping. When an annotator assigns an AOI label to a sequence of frames based on the respective fixation points, an interactive video object segmentation method is used to estimate the mask proposal of the AOI. Then, we use the 3D reconstruction of the visual scene created from the eye tracking video to map these AOI masks to 3D. The resulting 3D segmentation of the AOI can be used to suggest labels for the rest of the video, with the suggestions becoming increasingly accurate as more samples are provided by an annotator using interactive machine learning (IML). IMETA has the potential to reduce the annotation workload and speed up the evaluation of mobile eye tracking studies.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}

@inproceedings{13196,
title = {Interactive Fixation-to-AOI Mapping for Mobile Eye Tracking Data Based on Few-Shot Image Classification},
author = {Michael Barz and Omair Shahzad Bhatti and Hasan Md Tusfiqur Alam and Ho Minh Duy Nguyen and Daniel Sonntag},
url = {https://www.dfki.de/fileadmin/user_upload/import/13196_3581754.3584179.pdf},
doi = {https://doi.org/10.1145/3581754.3584179},
year = {2023},
date = {2023-01-01},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {175-178},
publisher = {Association for Computing Machinery},
abstract = {Mobile eye tracking is an important tool in psychology and human-centred interaction design for understanding how people process visual scenes and user interfaces. However, analysing recordings from mobile eye trackers, which typically include an egocentric video of the scene and a gaze signal, is a time-consuming and largely manual process. To address this challenge, we propose a web-based annotation tool that leverages few-shot image classification and interactive machine learning (IML) to accelerate the annotation process. The tool allows users to efficiently map fixations to areas of interest (AOI) in a video-editing-style interface. It includes an IML component that generates suggestions and learns from user feedback using a few-shot image classification model initialised with a small number of images per AOI. Our goal is to improve the efficiency and accuracy of fixation-to-AOI mapping in mobile eye tracking.},
keywords = {},
pubstate = {published},
tppubtype = {inproceedings}
}


@article{13195,
title = {Digital ink and differentiated subjective ratings for cognitive load measurement in middle childhood},
author = {Kristin Altmeyer and Michael Barz and Luisa Lauer and Markus Peschel and Daniel Sonntag and Roland Brünken and Sarah Malone},
url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/bjep.12595},
year = {2023},
date = {2023-01-01},
journal = {British Journal of Educational Psychology},
volume = {n/a},
pages = {18},
publisher = {John Wiley & Sons, Ltd},
abstract = {Abstract Background New methods are constantly being developed to adapt cognitive load measurement to different contexts. However, research on middle childhood students' cognitive load measurement is rare. Research indicates that the three cognitive load dimensions (intrinsic, extraneous, and germane) can be measured well in adults and teenagers using differentiated subjective rating instruments. Moreover, digital ink recorded by smartpens could serve as an indicator for cognitive load in adults. Aims With the present research, we aimed at investigating the relation between subjective cognitive load ratings, velocity and pressure measures recorded with a smartpen, and performance in standardized sketching tasks in middle childhood students. Sample Thirty-six children (age 7–12) participated at the university's laboratory. Methods The children performed two standardized sketching tasks, each in two versions. The induced intrinsic cognitive load or the extraneous cognitive load was varied between the versions. Digital ink was recorded while the children drew with a smartpen on real paper and after each task, they were asked to report their perceived intrinsic and extraneous cognitive load using a newly developed 5-item scale. Results Results indicated that cognitive load ratings as well as velocity and pressure measures were substantially related to the induced cognitive load and to performance in both sketching tasks. However, cognitive load ratings and smartpen measures were not substantially related. Conclusions Both subjective rating and digital ink hold potential for cognitive load and performance measurement. However, it is questionable whether they measure the exact same constructs.},
keywords = {},
pubstate = {published},
tppubtype = {article}
}

@inproceedings{pub12923,
    author = {Nguyen, Ho Minh Duy and Nguyen, Hoang and Truong, Mai T. N. and Cao, Tri and Nguyen, Binh T. and Ho, Nhat and Swoboda, Paul and Albarqouni, Shadiand Xie, Pengtao and Sonntag, Daniel},
    title = {Joint Self-Supervised Image-Volume Representation Learning with Intra-Inter Contrastive Clustering},
    booktitle = {Thirty-Seventh AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence (AAAI-2023)},
    year = {2023},
    month = {2},
    publisher = {AAAI Press}
}

